training loss,out_0,out_1,epoch,step
0.9361597895622253,-0.020746048539876938,0.03244649991393089,24,49
0.8075320720672607,0.02717118337750435,0.1013721227645874,49,99
0.6918832659721375,0.07125207781791687,0.16820475459098816,74,149
0.5892859101295471,0.11139379441738129,0.2323504090309143,99,199
0.49986013770103455,0.14662516117095947,0.29299214482307434,124,249
0.42309999465942383,0.17595472931861877,0.3495386242866516,149,299
0.3579302728176117,0.19866955280303955,0.40172725915908813,174,349
0.3029133975505829,0.21448500454425812,0.44962427020072937,199,399
0.2564864754676819,0.22356350719928741,0.49355506896972656,224,449
0.21715441346168518,0.22643731534481049,0.5340017080307007,249,499
0.18361158668994904,0.22389090061187744,0.5715007781982422,274,549
0.15479354560375214,0.21684540808200836,0.6065618991851807,299,599
0.12987761199474335,0.20626571774482727,0.6396146416664124,324,649
0.1082526445388794,0.19309353828430176,0.670982301235199,349,699
0.08947499096393585,0.17820051312446594,0.7008762955665588,374,749
0.07322085648775101,0.16235581040382385,0.729406476020813,399,799
0.05924389883875847,0.14620694518089294,0.7565993070602417,424,849
0.04734049364924431,0.13027183711528778,0.7824212908744812,449,899
0.037324994802474976,0.11494284868240356,0.8068032264709473,474,949
0.029015371575951576,0.10049790143966675,0.8296610116958618,499,999
