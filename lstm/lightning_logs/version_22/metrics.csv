training loss,out_0,out_1,epoch,step
1.1278085708618164,0.1266436129808426,-0.06198330223560333,24,49
1.043660044670105,0.14404483139514923,-0.02159680612385273,49,99
0.9728721976280212,0.16014301776885986,0.013657164759933949,74,149
0.9076284766197205,0.17742057144641876,0.04730464145541191,99,199
0.8404926657676697,0.19730375707149506,0.08321615308523178,124,249
0.7692812085151672,0.219196155667305,0.12291325628757477,149,299
0.6970114707946777,0.24150243401527405,0.16512790322303772,174,349
0.6281192302703857,0.26280108094215393,0.20746026933193207,199,399
0.5658490657806396,0.28220513463020325,0.24777060747146606,224,449
0.511615514755249,0.29931849241256714,0.28472700715065,249,499
0.465420126914978,0.314083456993103,0.3177829384803772,274,549
0.42649656534194946,0.3266323208808899,0.34693294763565063,299,599
0.3938010632991791,0.33718141913414,0.37246426939964294,324,649
0.3662870228290558,0.3459680378437042,0.39478346705436707,349,699
0.34302401542663574,0.353219211101532,0.41431745886802673,374,749
0.3232317268848419,0.3591383397579193,0.4314652383327484,399,799
0.3062748312950134,0.36390170454978943,0.4465790092945099,424,849
0.29164212942123413,0.367659330368042,0.4599609971046448,449,899
0.2789248824119568,0.37053897976875305,0.4718666076660156,474,949
0.2677959203720093,0.3726480305194855,0.4825100004673004,499,999
