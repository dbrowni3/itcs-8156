{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as fn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger as TensorBoardLogger\n",
    "import tensorboard\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from lstm_second import BasicLSTM\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's test our model with a super simple validation from the StatQuest guy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the training data for the neural network.\n",
    "inputs = torch.tensor([[[0., 0.5, 0.25, 1.]], [[1., 0.5, 0.25, 1.]]])\n",
    "labels = torch.tensor([0., 1.])\n",
    "\n",
    "dataset = TensorDataset(inputs, labels) \n",
    "dataloader = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_simple = BasicLSTM(num_feat=1, num_hiddens=1, num_out=1, lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Company A: Observed = 0, Predicted =\", \n",
    "      mdl_simple(torch.tensor([[0., 0.5, 0.25, 1.]])).detach())\n",
    "print(\"Company B: Observed = 1, Predicted =\", \n",
    "      mdl_simple(torch.tensor([[1., 0.5, 0.25, 1.]])).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"simpleModel\")\n",
    "\n",
    "trainer_simple = pl.Trainer(max_epochs=1000,logger=logger) # with default learning rate, 0.001 (this tiny learning rate makes learning slow)\n",
    "trainer_simple.fit(mdl_simple, train_dataloaders=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_simple.test(mdl_simple,dataloaders=dataloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's try to test our model with our stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.insert(1, r'C:\\Users\\Spenc\\Documents\\GitHub\\itcs-8156\\utils')\n",
    "\n",
    "from preprocessing import (market_prepro,\n",
    "                           lstm_timeseries_feat_and_targ,\n",
    "                           \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st = \"Stocks\"\n",
    "st = \"ETFs\"\n",
    "\n",
    "#Input stock name\n",
    "sn = \"aadr\" \n",
    "f = r'G:\\My Drive\\School\\UNCC\\P.h.D\\Coursework\\2023 - SPRING\\ITCS 8156 - Machine Learning\\Project\\archive'\n",
    "X_train, X_test, T_train, T_test = market_prepro(f,st,sn,False,splitdata=True, stdzr='minmax')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(T_train.shape)\n",
    "# X,T = market_prepro(f,st,sn,False,splitdata=False)\n",
    "\n",
    "#number of days as features\n",
    "day_feat = 2\n",
    "\n",
    "#number of days to use as features\n",
    "day_targ = 1\n",
    "day_targ = day_targ - 1\n",
    "\n",
    "# dl_train, ds_train = lstm_timeseries_feat_and_targ(X_train[['Open','Low']], T_train, 4, 1,None)\n",
    "# dl_test, ds_test = lstm_timeseries_feat_and_targ(X_test[['Open','Low']], T_test, 4, 1,  None)\n",
    "\n",
    "dl_train, ds_train = lstm_timeseries_feat_and_targ(X_train, T_train, day_feat, day_targ, [ 'Year', 'Month' ,'Day_date', 'Day'])\n",
    "dl_test, ds_test = lstm_timeseries_feat_and_targ(X_test, T_test, day_feat, day_targ, [ 'Year', 'Month' ,'Day_date', 'Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_stock = BasicLSTM(num_feat=7, num_hiddens=1, num_out=1, lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_stock.forward(ds_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"market\")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=10,logger=logger) # with default learning rate, 0.001 (this tiny learning rate makes learning slow)\n",
    "trainer.fit(mdl_stock, train_dataloaders=dl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(mdl_stock,dataloaders=dl_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at the tensorboard test loss vs step it seems like most of the loss is coming from later in the predictions (farther from the training data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def makepred(model, dataset):\n",
    "    y = []\n",
    "    t = []\n",
    "    for ii in dataset:\n",
    "        feat, lab = ii\n",
    "\n",
    "        y.append(model.forward(feat).detach().numpy()[0])\n",
    "        t.append(lab.numpy()[0])\n",
    "\n",
    "\n",
    "    return y, t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test, t_test = makepred(mdl_stock, ds_test)\n",
    "y_train, t_train = makepred(mdl_stock, ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "\n",
    "print('Training r2 ', r2_score(t_train, y_train) )\n",
    "print('Testing r2 ', r2_score(t_test, y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scatter_results(Y,T,title):\n",
    "    plt.figure(figsize=(9,9))\n",
    "    plt.scatter(Y,T)\n",
    "    plt.xlabel('Model Prediction')\n",
    "    plt.ylabel('True Value')\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_results(y_test, t_test, 'Testing')\n",
    "scatter_results(y_train, t_train, 'Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(t_test)),t_test)\n",
    "plt.plot(range(len(y_test)),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actfn_labels = (['Sigmoid', 'ReLU', 'LeakyReLU', 'ELU', 'SELU', 'arcsinh', 'Swish', 'Softplus', 'Mish', 'Comb-H-Sine', 'tanh'])\n",
    "\n",
    "results = []\n",
    "for i in range(len(actfn_labels)):\n",
    "    act1 = actfn_labels[i]\n",
    "\n",
    "    for j in range(len(actfn_labels)):\n",
    "        act2 = actfn_labels[j]\n",
    "        display(\"Activation Function 1: \", act1)\n",
    "        display(\"Activation Function 2: \", act2)\n",
    "        mdl_stock = BasicLSTM(num_feat=7, num_hiddens=1, num_out=1, lr=0.01, actfn1=act1, actfn2=act2)\n",
    "        mdl_stock.forward(ds_train[0][0])\n",
    "\n",
    "        logger = TensorBoardLogger(\"lightning_logs\", name=\"market\")\n",
    "        trainer = pl.Trainer(max_epochs=5,logger=logger) # with default learning rate, 0.001 (this tiny learning rate makes learning slow)\n",
    "        trainer.fit(mdl_stock, train_dataloaders=dl_train)\n",
    "        trainer.test(mdl_stock,dataloaders=dl_test)\n",
    "        torch.save(mdl_stock, act1+act2)\n",
    "\n",
    "        y_test, t_test = makepred(mdl_stock, ds_test)\n",
    "        y_train, t_train = makepred(mdl_stock, ds_train)\n",
    "\n",
    "        train_score = r2_score(t_train, y_train)\n",
    "        test_score = r2_score(t_test, y_test)\n",
    "\n",
    "        plt.plot(range(len(t_test)),t_test)\n",
    "        plt.plot(range(len(y_test)),y_test)\n",
    "\n",
    "        add_res = [act1, act2, train_score, test_score]\n",
    "\n",
    "        results.append(add_res)\n",
    "\n",
    "display(\"Activation Fn 1, Activation Fn 2, Training R2, Testing R2\")\n",
    "display(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"Activation Fn 1, Activation Fn 2, Training R2, Testing R2\")\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(results, 'ACT_FUNC_Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "res = pd.DataFrame(torch.load('ACT_FUNC_Results'))\n",
    "res.sort_values(3, ascending=True)\n",
    "display(res.sort_values(3,ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actfn_labels = (['Sigmoid', 'ReLU', 'LeakyReLU', 'ELU', 'SELU', 'arcsinh', 'Swish', 'Softplus', 'Mish', 'Comb-H-Sine', 'tanh'])\n",
    "train_map = pd.DataFrame(np.zeros([len(actfn_labels),len(actfn_labels)]))\n",
    "train_map.columns = actfn_labels\n",
    "train_map.index = actfn_labels\n",
    "\n",
    "test_map = pd.DataFrame(np.zeros([len(actfn_labels),len(actfn_labels)]))\n",
    "test_map.columns = actfn_labels\n",
    "test_map.index = actfn_labels\n",
    "\n",
    "for i in range(len(actfn_labels)):\n",
    "    actfn1 = actfn_labels[i]\n",
    "\n",
    "    for j in range(len(actfn_labels)):\n",
    "        actfn2 = actfn_labels[j]\n",
    "        train_map.iloc[i,j] = res.where((res[0]==actfn1)).where(res[1]==actfn2)[2].dropna()\n",
    "        test_map.iloc[i,j] = res.where((res[0]==actfn1)).where(res[1]==actfn2)[3].dropna()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_map, vmin=0.8, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(test_map, vmin=0.95, vmax=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that  we have determined the best activation functions, we can optimize the number of days we use as inputs.\n",
    "\n",
    "We have done our initial testing predicting 1 day forward from the previous day, we will continue to predit 1 day forward, but we will include more input days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from sklearn.metrics import r2_score\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.insert(1, r'C:\\Users\\Spenc\\Documents\\GitHub\\itcs-8156\\utils')\n",
    "\n",
    "from preprocessing import (market_prepro,\n",
    "                           lstm_timeseries_feat_and_targ,\n",
    "                           \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st = \"Stocks\"\n",
    "st = \"ETFs\"\n",
    "\n",
    "#Input stock name\n",
    "sn = \"aadr\" \n",
    "f = r'G:\\My Drive\\School\\UNCC\\P.h.D\\Coursework\\2023 - SPRING\\ITCS 8156 - Machine Learning\\Project\\archive'\n",
    "X_train, X_test, T_train, T_test = market_prepro(f,st,sn,False,splitdata=True, stdzr='minmax')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(T_train.shape)\n",
    "# X,T = market_prepro(f,st,sn,False,splitdata=False)\n",
    "\n",
    "actfn1 = ['Sigmoid']\n",
    "actfn2 = ['tanh']\n",
    "\n",
    "test_days = [2, 3, 5, 7, 10, 15, 20]\n",
    "\n",
    "for i in range(len(actfn1)):\n",
    "\n",
    "    act1fn1=actfn1[i]\n",
    "    act2fn2=actfn2[i]\n",
    "\n",
    "    for j in range(len(test_days)):\n",
    "        #number of days as features\n",
    "        day_feat = test_days[j]\n",
    "\n",
    "        #number of days to use as features\n",
    "        day_targ = 1\n",
    "        day_targ = day_targ - 1\n",
    "\n",
    "        # dl_train, ds_train = lstm_timeseries_feat_and_targ(X_train[['Open','Low']], T_train, 4, 1,None)\n",
    "        # dl_test, ds_test = lstm_timeseries_feat_and_targ(X_test[['Open','Low']], T_test, 4, 1,  None)\n",
    "\n",
    "        dl_train, ds_train = lstm_timeseries_feat_and_targ(X_train, T_train, day_feat, day_targ, [ 'Year', 'Month' ,'Day_date', 'Day'])\n",
    "        dl_test, ds_test = lstm_timeseries_feat_and_targ(X_test, T_test, day_feat, day_targ, [ 'Year', 'Month' ,'Day_date', 'Day'])\n",
    "\n",
    "        mdl_stock = BasicLSTM(num_feat=7, num_hiddens=1, num_out=1, lr=0.01, actfn1=act1fn1, actfn2=act2fn2)\n",
    "        mdl_stock.forward(ds_train[0][0])\n",
    "\n",
    "        logger = TensorBoardLogger(\"lightning_logs\", name=\"market\")\n",
    "        trainer = pl.Trainer(max_epochs=5,logger=logger) # with default learning rate, 0.001 (this tiny learning rate makes learning slow)\n",
    "        trainer.fit(mdl_stock, train_dataloaders=dl_train)\n",
    "        trainer.test(mdl_stock,dataloaders=dl_test)\n",
    "        torch.save(mdl_stock, act1fn1+act2fn2+str(day_feat))\n",
    "\n",
    "        y_test, t_test = makepred(mdl_stock, ds_test)\n",
    "        y_train, t_train = makepred(mdl_stock, ds_train)\n",
    "\n",
    "        train_score = r2_score(t_train, y_train)\n",
    "        test_score = r2_score(t_test, y_test)\n",
    "\n",
    "        add_res_sweep = [act1fn1, act2fn2, day_feat, train_score, test_score]\n",
    "\n",
    "        results_daysweep.append(add_res_sweep)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: LeakyReLU-ELU does not appear to work on higher number of input days. Max run was 15 days, blew up to epoch loss of inf the first time at 10 input days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(results_daysweep, 'Day Input Sweep Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep = pd.DataFrame(results_daysweep)\n",
    "display(sweep.sort_values(4, ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_res=pd.DataFrame(results_daysweep)\n",
    "train_sweep = sweep_res.where(sweep_res[0] == 'SELU').dropna()\n",
    "plt.figure()\n",
    "plt.suptitle('SELU - Sigmoid')\n",
    "plt.subplot(121)\n",
    "plt.plot(train_sweep[2], train_sweep[3])\n",
    "plt.xlim([0,20])\n",
    "plt.ylim([-1,1])\n",
    "plt.title('Training')\n",
    "plt.xlabel('# of input days')\n",
    "plt.ylabel('r2 score')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(train_sweep[2], train_sweep[4])\n",
    "plt.xlim([0,20])\n",
    "plt.ylim([-1,1])\n",
    "plt.title('Testing')\n",
    "plt.xlabel('# of input days')\n",
    "plt.ylabel('r2 score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sweep = sweep_res.where(sweep_res[0] == 'ReLU').dropna()\n",
    "plt.figure()\n",
    "plt.suptitle('ReLU - Sigmoid')\n",
    "plt.subplot(121)\n",
    "plt.plot(train_sweep[2], train_sweep[3])\n",
    "plt.xlim([0,20])\n",
    "plt.ylim([-1,1])\n",
    "plt.title('Training')\n",
    "plt.xlabel('# of input days')\n",
    "plt.ylabel('r2 score')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(train_sweep[2], train_sweep[4])\n",
    "plt.xlim([0,20])\n",
    "plt.ylim([-1,1])\n",
    "plt.title('Testing')\n",
    "plt.xlabel('# of input days')\n",
    "plt.ylabel('r2 score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sweep = sweep_res.where(sweep_res[0] == 'LeakyReLU').dropna()\n",
    "plt.figure()\n",
    "plt.suptitle('LeakyReLU - ELU')\n",
    "plt.subplot(121)\n",
    "plt.plot(train_sweep[2], train_sweep[3])\n",
    "plt.xlim([0,20])\n",
    "plt.ylim([-1,1])\n",
    "plt.title('Training')\n",
    "plt.xlabel('# of input days')\n",
    "plt.ylabel('r2 score')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(train_sweep[2], train_sweep[4])\n",
    "plt.xlim([0,20])\n",
    "plt.ylim([-1,1])\n",
    "plt.title('Testing')\n",
    "plt.xlabel('# of input days')\n",
    "plt.ylabel('r2 score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sweep = sweep_res.where(sweep_res[0] == 'Mish').dropna()\n",
    "plt.figure()\n",
    "plt.suptitle('Mish - Sigmoid')\n",
    "plt.subplot(121)\n",
    "plt.plot(train_sweep[2], train_sweep[3])\n",
    "plt.xlim([0,20])\n",
    "plt.ylim([0.5,1])\n",
    "plt.title('Training')\n",
    "plt.xlabel('# of input days')\n",
    "plt.ylabel('r2 score')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(train_sweep[2], train_sweep[4])\n",
    "plt.xlim([0,20])\n",
    "plt.ylim([0.5,1])\n",
    "plt.title('Testing')\n",
    "plt.xlabel('# of input days')\n",
    "plt.ylabel('r2 score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sweep = sweep_res.where(sweep_res[0] == 'arcsinh').dropna()\n",
    "plt.figure()\n",
    "plt.suptitle('arcsinh - tanh')\n",
    "plt.subplot(121)\n",
    "plt.plot(train_sweep[2], train_sweep[3])\n",
    "plt.xlim([0,20])\n",
    "plt.ylim([0.5,1])\n",
    "plt.title('Training')\n",
    "plt.xlabel('# of input days')\n",
    "plt.ylabel('r2 score')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(train_sweep[2], train_sweep[4])\n",
    "plt.xlim([0,20])\n",
    "plt.ylim([0.5,1])\n",
    "plt.title('Testing')\n",
    "plt.xlabel('# of input days')\n",
    "plt.ylabel('r2 score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sweep = sweep_res.where(sweep_res[0] == 'Sigmoid').dropna()\n",
    "plt.figure()\n",
    "plt.title('Sigmoid - tanh or BASE LSTM')\n",
    "plt.subplot(121)\n",
    "plt.plot(train_sweep[2], train_sweep[3])\n",
    "plt.xlim([0,20])\n",
    "plt.ylim([0.5,1])\n",
    "plt.title('Training')\n",
    "plt.xlabel('# of input days')\n",
    "plt.ylabel('r2 score')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(train_sweep[2], train_sweep[4])\n",
    "plt.xlim([0,20])\n",
    "plt.ylim([0.5,1])\n",
    "plt.title('Testing')\n",
    "plt.xlabel('# of input days')\n",
    "plt.ylabel('r2 score')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# after considering the above plots, it appears that the best working model is the Mish-Sigmoid model with either 2,3, or 15 days of input data.\n",
    "\n",
    "As such, we will train this model for 10 epochs and will attempt to use the same model on other stocks and determine the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stock_sweep = []\n",
    "\n",
    "# st = \"Stocks\"\n",
    "st = \"ETFs\"\n",
    "\n",
    "#Input stock name\n",
    "stock_names = [\"aadr\", \"aaxj\", \"acim\", \"actx\", \"acwf\"]\n",
    "\n",
    "actfn1 = ['Sigmoid', 'Mish', 'Mish']\n",
    "actfn2 = ['tanh', 'Sigmoid', 'Sigmoid']\n",
    "\n",
    "test_days = [3, 3, 15]\n",
    "\n",
    "for i in range(len(actfn1)):\n",
    "\n",
    "    act1fn1=actfn1[i]\n",
    "    act2fn2=actfn2[i]\n",
    "    #number of days as features\n",
    "    day_feat = test_days[i]\n",
    "    #number of days to use as features\n",
    "    day_targ = 1\n",
    "    day_targ = day_targ - 1\n",
    "    \n",
    "    for j in range(len(stock_names)):\n",
    "\n",
    "        sn = stock_names[j]\n",
    "        f = r'G:\\My Drive\\School\\UNCC\\P.h.D\\Coursework\\2023 - SPRING\\ITCS 8156 - Machine Learning\\Project\\archive'\n",
    "        X_train, X_test, T_train, T_test = market_prepro(f,st,sn,False,splitdata=True, stdzr='minmax')\n",
    "\n",
    "        # dl_train, ds_train = lstm_timeseries_feat_and_targ(X_train[['Open','Low']], T_train, 4, 1,None)\n",
    "        # dl_test, ds_test = lstm_timeseries_feat_and_targ(X_test[['Open','Low']], T_test, 4, 1,  None)\n",
    "\n",
    "        dl_train, ds_train = lstm_timeseries_feat_and_targ(X_train, T_train, day_feat, day_targ, [ 'Year', 'Month' ,'Day_date', 'Day'])\n",
    "        dl_test, ds_test = lstm_timeseries_feat_and_targ(X_test, T_test, day_feat, day_targ, [ 'Year', 'Month' ,'Day_date', 'Day'])\n",
    "\n",
    "        mdl_stock = BasicLSTM(num_feat=7, num_hiddens=1, num_out=1, lr=0.01, actfn1=act1fn1, actfn2=act2fn2)\n",
    "        mdl_stock.forward(ds_train[0][0])\n",
    "\n",
    "        logger = TensorBoardLogger(\"lightning_logs\", name=\"market\")\n",
    "        trainer = pl.Trainer(max_epochs=10,logger=logger) # with default learning rate, 0.001 (this tiny learning rate makes learning slow)\n",
    "        trainer.fit(mdl_stock, train_dataloaders=dl_train)\n",
    "        trainer.test(mdl_stock,dataloaders=dl_test)\n",
    "        torch.save(mdl_stock, act1fn1+act2fn2+str(day_feat)+sn)\n",
    "\n",
    "        y_test, t_test = makepred(mdl_stock, ds_test)\n",
    "        y_train, t_train = makepred(mdl_stock, ds_train)\n",
    "\n",
    "        train_score = r2_score(t_train, y_train)\n",
    "        test_score = r2_score(t_test, y_test)\n",
    "\n",
    "        add_res_sweep = [act1fn1, act2fn2, sn, day_feat, train_score, test_score]\n",
    "\n",
    "        results_stock_sweep.append(add_res_sweep)\n",
    "\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(range(len(t_test)),t_test)\n",
    "        plt.plot(range(len(y_test)),y_test)\n",
    "        plt.title(act1fn1+act2fn2+' '+str(day_feat)+' '+sn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(results_stock_sweep, 'Stock Sweep Results')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
